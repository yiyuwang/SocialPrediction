{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Level Analysis for Social Prediction\n",
    "\n",
    "2024 February\n",
    "\n",
    "*Yiyu Wang*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyuwang/anaconda3/envs/neuroimaging_env/lib/python3.7/site-packages/nilearn/__init__.py:67: FutureWarning: Python 3.7 support is deprecated and will be removed in release 0.12 of Nilearn. Consider switching to Python 3.9 or 3.10.\n",
      "  _python_deprecation_warnings()\n",
      "/Users/yiyuwang/anaconda3/envs/neuroimaging_env/lib/python3.7/site-packages/nilearn/input_data/__init__.py:23: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import nilearn\n",
    "from nilearn import datasets, plotting, image\n",
    "from nilearn.image import smooth_img, resample_to_img\n",
    "from nilearn import plotting\n",
    "from nilearn.masking import apply_mask\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "import gzip\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.2\n"
     ]
    }
   ],
   "source": [
    "print(nilearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects in this analysis:\n",
      "[152, 179, 154, 158, 173, 153, 159, 174, 162, 145, 143, 181, 144, 169, 146, 167, 161, 182, 147, 166, 160, 185, 170, 176, 151, 157, 171, 177, 150, 156]\n",
      "**** n = 30 *****\n"
     ]
    }
   ],
   "source": [
    "# local directory set up\n",
    "#data_dir =base_dir + 'transformed_data_2mm/'\n",
    "\n",
    "# directory set up for cluster:\n",
    "# base_dir = '/scratch/wang.yiyu/SocialAbstraction/'\n",
    "data_dir = '/Users/yiyuwang/Downloads/social_prediction_transformed_data_2mm/'\n",
    "\n",
    "logfiles_dir = '../Data/logfiles/'\n",
    "confounds_dir = '../Data/confounds/'\n",
    "mask_dir = '../masks/'\n",
    "figures_dir = 'figures/'\n",
    "\n",
    "subjects_list = pd.read_csv('../Data/included_SocialPred_subjects.csv', header=None)\n",
    "subjects_list = subjects_list[0].values.tolist()\n",
    "sample_n = len(subjects_list)\n",
    "print(\"subjects in this analysis:\")\n",
    "print(subjects_list)\n",
    "print(f\"**** n = {sample_n} *****\" )\n",
    "\n",
    "vmax = 12\n",
    "TR = .001\n",
    "N_TR = 675\n",
    "TR_Length = 0.8\n",
    "TR_IN_MS = int(TR_Length/TR)\n",
    "\n",
    "fwhm = 8\n",
    "\n",
    "# resample a gray matter mask\n",
    "gm_mask_img = nib.load(mask_dir + 'gm_mask_icbm152_brain.nii.gz')\n",
    "confounds_of_interest = ['csf',\n",
    "                        'white_matter',\n",
    "                        'trans_x', \n",
    "                        'trans_y', \n",
    "                        'trans_z',\n",
    "                        'rot_x',\n",
    "                        'rot_y',\n",
    "                        'rot_z','framewise_displacement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile_headers =np.array(['obs_video_name', 'fd_video_name','video_number','trial_condition','run_number','run_condition',\n",
    "             'obs_video_onset','obs_video_offset','obs_video_duration_method1','obs_video_duration_method2',\n",
    "             'prediction','prediction_x','prediction_y','prediction_RT','prediction_onset', \n",
    "             'fb_video_onset','fb_video_offset','fb_video_duration_method1','fb_video_duration_method2',\n",
    "             'surprise','surprise_RT','surprise_onset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddSteadyStateOutliers(columns_of_interest, all_columns):\n",
    "    new_columns = copy.deepcopy(columns_of_interest)\n",
    "    for column in all_columns:\n",
    "        if 'outlier' in column:\n",
    "            new_columns.append(column) \n",
    "    return new_columns\n",
    "\n",
    "\n",
    "\n",
    "def CreateConfoundMatrix(confound_file_path, \n",
    "                         confounds_of_interest, s, run):\n",
    "    \n",
    "    \n",
    "    confounds = pd.read_csv(confound_file_path, sep='\\t')\n",
    "    \n",
    "    confounds_of_interest = AddSteadyStateOutliers(confounds_of_interest, confounds.columns)\n",
    "    \n",
    "    cov = confounds[confounds_of_interest]\n",
    "    cov.values[np.isnan(cov.values)]=0\n",
    "    return cov\n",
    "\n",
    "\n",
    "video_key = pd.read_csv('/Users/yiyuwang/Dropbox/Projects/NEU_projects/SocialPrediction/results/SocialPrediction_video_key.csv')\n",
    "def get_subjective_prior(prediction, vn, video_key = video_key):\n",
    "    social_prior = video_key[video_key.vid_num == vn]['Social_correct'].values[0]\n",
    "    pattern_prior = video_key[video_key.vid_num == vn]['Pattern_correct'].values[0]\n",
    "    if prediction == social_prior:\n",
    "        return 2, 'Social'\n",
    "    elif prediction == pattern_prior:\n",
    "        return 1, 'Pattern'\n",
    "    else:\n",
    "        return 0, 'Neither'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_condition(cn):\n",
    "    if cn == 1:\n",
    "        cat = 'Pattern'\n",
    "    elif cn == 2:\n",
    "        cat = 'Social'\n",
    "    else:\n",
    "        print('no such Condition number!')\n",
    "    return cat \n",
    "\n",
    "def parse_task_lines(lines, headers):\n",
    "    for (i, line) in enumerate(lines):\n",
    "        cols = line.split(' ')\n",
    "\n",
    "        video_number = cols[int(np.where(headers == 'video_number')[0])]\n",
    "        \n",
    "        trial_condition = int(cols[int(np.where(headers == 'trial_condition')[0])])\n",
    "        trial_condition = get_condition(trial_condition)\n",
    "        \n",
    "        run_condition = int(cols[int(np.where(headers == 'run_condition')[0])])\n",
    "        run_condition = get_condition(run_condition)\n",
    "\n",
    "        prediction = int(abs(float(cols[int(np.where(headers == 'prediction')[0])])))\n",
    "        print(\"prediction: \", prediction)\n",
    "        _, subjective_prior_condition = get_subjective_prior(prediction, int(video_number))\n",
    "        \n",
    "\n",
    "        obs_trial_type = 'obs_' + subjective_prior_condition\n",
    "\n",
    "        # correct w\n",
    "        # congruent means trial_condition == run_condition\n",
    "        if subjective_prior_condition == trial_condition:\n",
    "            if trial_condition == 'Pattern':\n",
    "                fb_trial_type = 'fb_Pattern_Congruent'\n",
    "            elif trial_condition == 'Social':\n",
    "                fb_trial_type = 'fb_Social_Congruent'\n",
    "            \n",
    "        else: # PE means trial_condition != run_condition\n",
    "            if trial_condition == 'Pattern':\n",
    "                fb_trial_type = 'fb_Social_PE'\n",
    "            elif trial_condition == 'Social':\n",
    "                fb_trial_type = 'fb_Pattern_PE'\n",
    "        \n",
    "        video_onset = float(cols[int(np.where(headers == 'obs_video_onset')[0])])\n",
    "        video_offset = float(cols[int(np.where(headers == 'obs_video_offset')[0])])  \n",
    "        video_duration = video_offset - video_onset\n",
    "        \n",
    "        fb_video_onset = float(cols[int(np.where(headers == 'fb_video_onset')[0])])\n",
    "        fb_video_offset = float(cols[int(np.where(headers == 'fb_video_offset')[0])])  \n",
    "        fb_video_duration = fb_video_offset - fb_video_onset\n",
    "\n",
    "        run = int(cols[int(np.where(headers == 'run_number')[0])])\n",
    "\n",
    "        prediction_onset = float(cols[int(np.where(headers == 'prediction_onset')[0])])\n",
    "        surprise_onset = float(cols[int(np.where(headers == 'surprise_onset')[0])])\n",
    "        \n",
    "        yield [video_onset, video_duration, obs_trial_type, run]\n",
    "        yield [fb_video_onset,fb_video_duration, fb_trial_type, run]\n",
    "        yield [surprise_onset, 1, 'surprise_onset', run]\n",
    "        yield [prediction_onset, 1, 'pred_onset', run]\n",
    "\n",
    "            \n",
    "\n",
    "def create_events_dataframe(task_csv, run):   \n",
    "    task_lines =[]       \n",
    "    # df = pd.DataFrame(columns=['onset','duration','trial_type'])\n",
    "    with open(task_csv, 'r') as task_csv_file:\n",
    "        task_lines.append(list(parse_task_lines(task_csv_file.readlines()[0:], logfile_headers)))\n",
    "\n",
    "    df = pd.DataFrame(task_lines[0], columns=['onset','duration','trial_type','run'])\n",
    "    df= df[df['run']==run].drop(columns=['run'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running subject 179\n",
      "prediction:  5\n",
      "prediction:  4\n",
      "prediction:  3\n",
      "prediction:  2\n",
      "prediction:  5\n",
      "prediction:  2\n",
      "prediction:  2\n",
      "prediction:  3\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  4\n",
      "prediction:  2\n",
      "prediction:  4\n",
      "prediction:  4\n",
      "prediction:  3\n",
      "prediction:  3\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  3\n",
      "prediction:  1\n",
      "prediction:  1\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  4\n",
      "prediction:  5\n",
      "prediction:  2\n",
      "prediction:  2\n",
      "prediction:  3\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  4\n",
      "prediction:  1\n",
      "prediction:  2\n",
      "prediction:  1\n",
      "prediction:  5\n",
      "prediction:  1\n",
      "prediction:  5\n",
      "prediction:  4\n",
      "prediction:  3\n",
      "prediction:  2\n",
      "prediction:  5\n",
      "prediction:  2\n",
      "prediction:  2\n",
      "prediction:  3\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  4\n",
      "prediction:  2\n",
      "prediction:  4\n",
      "prediction:  4\n",
      "prediction:  3\n",
      "prediction:  3\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  3\n",
      "prediction:  1\n",
      "prediction:  1\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  4\n",
      "prediction:  5\n",
      "prediction:  2\n",
      "prediction:  2\n",
      "prediction:  3\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  3\n",
      "prediction:  4\n",
      "prediction:  4\n",
      "prediction:  1\n",
      "prediction:  2\n",
      "prediction:  1\n",
      "prediction:  5\n",
      "prediction:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res_dir = f'fmri_results/1stLvl_SubjectivePrior/'\n",
    "if not os.path.isdir(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "\n",
    "for s in subjects_list[1:2]:\n",
    "    print(f'running subject {s}')\n",
    "    sub_output_dir = res_dir + f'/{s}/'\n",
    "    if not os.path.isdir(sub_output_dir):\n",
    "        os.makedirs(sub_output_dir)\n",
    "        \n",
    "    task_file = glob.glob(logfiles_dir + f\"/*{s}*edited.txt\")\n",
    "    task_csv = task_file[0]\n",
    "    \n",
    "    for run in [1,2]:\n",
    "        events = create_events_dataframe(task_csv, run)\n",
    "\n",
    "        #get confounds info:\n",
    "        confounds_str = f'sub-{s}_task-socialpred_run-{run}_desc-confounds_timeseries.tsv'\n",
    "        cov = CreateConfoundMatrix(confounds_dir + confounds_str, confounds_of_interest, s, run)\n",
    "        \n",
    "        fmri_glm = FirstLevelModel(t_r=TR_Length,\n",
    "                           noise_model='ar3',\n",
    "                           standardize=True,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.012, mask_img=gm_mask_img,smoothing_fwhm=8)\n",
    "        \n",
    "        func_str = f'sub-{s}_socialpred_run{run}.nii.gz'\n",
    "        func_path = data_dir + func_str\n",
    "        fmri_img = nib.load(func_path)\n",
    "        fmri_glm = fmri_glm.fit(fmri_img, events, confounds=cov)\n",
    "        \n",
    "        # save design_matrix for every run\n",
    "        design_matrix = fmri_glm.design_matrices_[0]\n",
    "\n",
    "        plotting.plot_design_matrix(design_matrix, output_file=join(sub_output_dir, f'design_matrix_run{run}.png'))\n",
    "        contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "        # # extract the betas\n",
    "        # for i in range(3):\n",
    "        #     print(f'saving regressor for video {design_matrix.columns[i]}')\n",
    "        #     eff = fmri_glm.compute_contrast(contrast_matrix[i],output_type='effect_size')\n",
    "        #     nii_file_path = sub_output_dir + f'/sub-{s}_run-{run}_beta_video-{design_matrix.columns[i]}_gm_masked.nii.gz'\n",
    "        #     nib.save(eff, nii_file_path)\n",
    "\n",
    "        #     eff = fmri_glm.compute_contrast(contrast_matrix[i],output_type='z_score')\n",
    "        #     nii_file_path = sub_output_dir + f'/sub-{s}_run-{run}_z_score_video-{design_matrix.columns[i]}_gm_masked.nii.gz'\n",
    "        #     nib.save(eff, nii_file_path)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fb_Pattern_Congruent</th>\n",
       "      <th>fb_Pattern_PE</th>\n",
       "      <th>fb_Social_Congruent</th>\n",
       "      <th>fb_Social_PE</th>\n",
       "      <th>obs_Neither</th>\n",
       "      <th>obs_Pattern</th>\n",
       "      <th>obs_Social</th>\n",
       "      <th>pred_onset</th>\n",
       "      <th>surprise_onset</th>\n",
       "      <th>csf</th>\n",
       "      <th>...</th>\n",
       "      <th>drift_4</th>\n",
       "      <th>drift_5</th>\n",
       "      <th>drift_6</th>\n",
       "      <th>drift_7</th>\n",
       "      <th>drift_8</th>\n",
       "      <th>drift_9</th>\n",
       "      <th>drift_10</th>\n",
       "      <th>drift_11</th>\n",
       "      <th>drift_12</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8044.540034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054431</td>\n",
       "      <td>0.054429</td>\n",
       "      <td>0.054428</td>\n",
       "      <td>0.054426</td>\n",
       "      <td>0.054424</td>\n",
       "      <td>0.054421</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>0.054415</td>\n",
       "      <td>0.054412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7754.651725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054412</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.054385</td>\n",
       "      <td>0.054368</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.054326</td>\n",
       "      <td>0.054301</td>\n",
       "      <td>0.054273</td>\n",
       "      <td>0.054242</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7496.270029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054374</td>\n",
       "      <td>0.054341</td>\n",
       "      <td>0.054301</td>\n",
       "      <td>0.054253</td>\n",
       "      <td>0.054197</td>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.054065</td>\n",
       "      <td>0.053988</td>\n",
       "      <td>0.053903</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7336.634343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054318</td>\n",
       "      <td>0.054253</td>\n",
       "      <td>0.054173</td>\n",
       "      <td>0.054080</td>\n",
       "      <td>0.053972</td>\n",
       "      <td>0.053849</td>\n",
       "      <td>0.053712</td>\n",
       "      <td>0.053562</td>\n",
       "      <td>0.053396</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7283.391797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054242</td>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.054004</td>\n",
       "      <td>0.053849</td>\n",
       "      <td>0.053671</td>\n",
       "      <td>0.053469</td>\n",
       "      <td>0.053244</td>\n",
       "      <td>0.052995</td>\n",
       "      <td>0.052723</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>7187.478079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054242</td>\n",
       "      <td>-0.054135</td>\n",
       "      <td>0.054004</td>\n",
       "      <td>-0.053849</td>\n",
       "      <td>0.053671</td>\n",
       "      <td>-0.053469</td>\n",
       "      <td>0.053244</td>\n",
       "      <td>-0.052995</td>\n",
       "      <td>0.052723</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536.8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>7184.884086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054318</td>\n",
       "      <td>-0.054253</td>\n",
       "      <td>0.054173</td>\n",
       "      <td>-0.054080</td>\n",
       "      <td>0.053972</td>\n",
       "      <td>-0.053849</td>\n",
       "      <td>0.053712</td>\n",
       "      <td>-0.053562</td>\n",
       "      <td>0.053396</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537.6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7191.460818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054374</td>\n",
       "      <td>-0.054341</td>\n",
       "      <td>0.054301</td>\n",
       "      <td>-0.054253</td>\n",
       "      <td>0.054197</td>\n",
       "      <td>-0.054135</td>\n",
       "      <td>0.054065</td>\n",
       "      <td>-0.053988</td>\n",
       "      <td>0.053903</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538.4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7192.847100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054412</td>\n",
       "      <td>-0.054400</td>\n",
       "      <td>0.054385</td>\n",
       "      <td>-0.054368</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>-0.054326</td>\n",
       "      <td>0.054301</td>\n",
       "      <td>-0.054273</td>\n",
       "      <td>0.054242</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539.2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7193.890198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054431</td>\n",
       "      <td>-0.054429</td>\n",
       "      <td>0.054428</td>\n",
       "      <td>-0.054426</td>\n",
       "      <td>0.054424</td>\n",
       "      <td>-0.054421</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>-0.054415</td>\n",
       "      <td>0.054412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>675 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fb_Pattern_Congruent  fb_Pattern_PE  fb_Social_Congruent  fb_Social_PE  \\\n",
       "0.0                     0.0            0.0             0.000000           0.0   \n",
       "0.8                     0.0            0.0             0.000000           0.0   \n",
       "1.6                     0.0            0.0             0.000000           0.0   \n",
       "2.4                     0.0            0.0             0.000000           0.0   \n",
       "3.2                     0.0            0.0             0.000000           0.0   \n",
       "...                     ...            ...                  ...           ...   \n",
       "536.0                   0.0            0.0            -0.000023           0.0   \n",
       "536.8                   0.0            0.0             0.000000           0.0   \n",
       "537.6                   0.0            0.0             0.000000           0.0   \n",
       "538.4                   0.0            0.0             0.000000           0.0   \n",
       "539.2                   0.0            0.0             0.000000           0.0   \n",
       "\n",
       "       obs_Neither  obs_Pattern  obs_Social  pred_onset  surprise_onset  \\\n",
       "0.0            0.0          0.0         0.0         0.0        0.000000   \n",
       "0.8            0.0          0.0         0.0         0.0        0.000000   \n",
       "1.6            0.0          0.0         0.0         0.0        0.000000   \n",
       "2.4            0.0          0.0         0.0         0.0        0.000000   \n",
       "3.2            0.0          0.0         0.0         0.0        0.000000   \n",
       "...            ...          ...         ...         ...             ...   \n",
       "536.0          0.0          0.0         0.0         0.0       -0.000115   \n",
       "536.8          0.0          0.0         0.0         0.0       -0.000043   \n",
       "537.6          0.0          0.0         0.0         0.0        0.000000   \n",
       "538.4          0.0          0.0         0.0         0.0        0.000000   \n",
       "539.2          0.0          0.0         0.0         0.0        0.000000   \n",
       "\n",
       "               csf  ...   drift_4   drift_5   drift_6   drift_7   drift_8  \\\n",
       "0.0    8044.540034  ...  0.054431  0.054429  0.054428  0.054426  0.054424   \n",
       "0.8    7754.651725  ...  0.054412  0.054400  0.054385  0.054368  0.054348   \n",
       "1.6    7496.270029  ...  0.054374  0.054341  0.054301  0.054253  0.054197   \n",
       "2.4    7336.634343  ...  0.054318  0.054253  0.054173  0.054080  0.053972   \n",
       "3.2    7283.391797  ...  0.054242  0.054135  0.054004  0.053849  0.053671   \n",
       "...            ...  ...       ...       ...       ...       ...       ...   \n",
       "536.0  7187.478079  ...  0.054242 -0.054135  0.054004 -0.053849  0.053671   \n",
       "536.8  7184.884086  ...  0.054318 -0.054253  0.054173 -0.054080  0.053972   \n",
       "537.6  7191.460818  ...  0.054374 -0.054341  0.054301 -0.054253  0.054197   \n",
       "538.4  7192.847100  ...  0.054412 -0.054400  0.054385 -0.054368  0.054348   \n",
       "539.2  7193.890198  ...  0.054431 -0.054429  0.054428 -0.054426  0.054424   \n",
       "\n",
       "        drift_9  drift_10  drift_11  drift_12  constant  \n",
       "0.0    0.054421  0.054418  0.054415  0.054412       1.0  \n",
       "0.8    0.054326  0.054301  0.054273  0.054242       1.0  \n",
       "1.6    0.054135  0.054065  0.053988  0.053903       1.0  \n",
       "2.4    0.053849  0.053712  0.053562  0.053396       1.0  \n",
       "3.2    0.053469  0.053244  0.052995  0.052723       1.0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "536.0 -0.053469  0.053244 -0.052995  0.052723       1.0  \n",
       "536.8 -0.053849  0.053712 -0.053562  0.053396       1.0  \n",
       "537.6 -0.054135  0.054065 -0.053988  0.053903       1.0  \n",
       "538.4 -0.054326  0.054301 -0.054273  0.054242       1.0  \n",
       "539.2 -0.054421  0.054418 -0.054415  0.054412       1.0  \n",
       "\n",
       "[675 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
