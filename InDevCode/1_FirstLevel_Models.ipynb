{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Level Analysis for Social Prediction\n",
    "\n",
    "2024 February\n",
    "\n",
    "*Yiyu Wang*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyuwang/anaconda3/envs/neuroimaging_env/lib/python3.7/site-packages/nilearn/__init__.py:67: FutureWarning: Python 3.7 support is deprecated and will be removed in release 0.12 of Nilearn. Consider switching to Python 3.9 or 3.10.\n",
      "  _python_deprecation_warnings()\n",
      "/Users/yiyuwang/anaconda3/envs/neuroimaging_env/lib/python3.7/site-packages/nilearn/input_data/__init__.py:23: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import nilearn\n",
    "from nilearn import datasets, plotting, image\n",
    "from nilearn.image import smooth_img, resample_to_img\n",
    "from nilearn import plotting\n",
    "from nilearn.masking import apply_mask\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "import gzip\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.2\n"
     ]
    }
   ],
   "source": [
    "print(nilearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects in this analysis:\n",
      "[152, 179, 154, 158, 173, 153, 159, 174, 162, 145, 143, 181, 144, 169, 146, 167, 161, 182, 147, 166, 160, 185, 170, 176, 151, 157, 171, 177, 150, 156]\n",
      "**** n = 30 *****\n"
     ]
    }
   ],
   "source": [
    "# local directory set up\n",
    "#data_dir =base_dir + 'transformed_data_2mm/'\n",
    "\n",
    "# directory set up for cluster:\n",
    "# base_dir = '/scratch/wang.yiyu/SocialAbstraction/'\n",
    "data_dir = '/Users/yiyuwang/Downloads/transformed_data_2mm/'\n",
    "\n",
    "logfiles_dir = 'Data/logfiles/'\n",
    "confounds_dir = 'Data/confounds/'\n",
    "mask_dir = 'masks/'\n",
    "figures_dir = 'figures/'\n",
    "\n",
    "subjects_list = pd.read_csv('Data/included_SocialPred_subjects.csv', header=None)\n",
    "subjects_list = subjects_list[0].values.tolist()\n",
    "sample_n = len(subjects_list)\n",
    "print(\"subjects in this analysis:\")\n",
    "print(subjects_list)\n",
    "print(f\"**** n = {sample_n} *****\" )\n",
    "\n",
    "vmax = 12\n",
    "TR = .001\n",
    "N_TR = 675\n",
    "TR_Length = 0.8\n",
    "TR_IN_MS = int(TR_Length/TR)\n",
    "\n",
    "fwhm = 8\n",
    "\n",
    "# resample a gray matter mask\n",
    "gm_mask_img = nib.load(mask_dir + 'gm_mask_icbm152_brain.nii.gz')\n",
    "confounds_of_interest = ['csf',\n",
    "                        'white_matter',\n",
    "                        'trans_x', \n",
    "                        'trans_y', \n",
    "                        'trans_z',\n",
    "                        'rot_x',\n",
    "                        'rot_y',\n",
    "                        'rot_z','framewise_displacement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile_headers =np.array(['obs_video_name', 'fd_video_name','video_number','trial_condition','run_number','run_condition',\n",
    "             'obs_video_onset','obs_video_offset','obs_video_duration_method1','obs_video_duration_method2',\n",
    "             'prediction','prediction_x','prediction_y','prediction_RT','prediction_onset', \n",
    "             'fb_video_onset','fb_video_offset','fb_video_duration_method1','fb_video_duration_method2',\n",
    "             'surprise','surprise_RT','surprise_onset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddSteadyStateOutliers(columns_of_interest, all_columns):\n",
    "    new_columns = copy.deepcopy(columns_of_interest)\n",
    "    for column in all_columns:\n",
    "        if 'outlier' in column:\n",
    "            new_columns.append(column) \n",
    "    return new_columns\n",
    "\n",
    "\n",
    "\n",
    "def CreateConfoundMatrix(confound_file_path, \n",
    "                         confounds_of_interest, s, run):\n",
    "    \n",
    "    \n",
    "    confounds = pd.read_csv(confound_file_path, sep='\\t')\n",
    "    \n",
    "    confounds_of_interest = AddSteadyStateOutliers(confounds_of_interest, confounds.columns)\n",
    "    \n",
    "    cov = confounds[confounds_of_interest]\n",
    "    cov.values[np.isnan(cov.values)]=0\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_condition(cn):\n",
    "    if cn == 1:\n",
    "        cat = 'Pattern'\n",
    "    elif cn == 2:\n",
    "        cat = 'Social'\n",
    "    else:\n",
    "        print('no such Condition number!')\n",
    "    return cat \n",
    "\n",
    "def parse_task_lines(lines, headers):\n",
    "    for (i, line) in enumerate(lines):\n",
    "        cols = line.split(' ')\n",
    "\n",
    "        video_number = cols[int(np.where(headers == 'video_number')[0])]\n",
    "        \n",
    "        trial_condition = int(cols[int(np.where(headers == 'trial_condition')[0])])\n",
    "        trial_condition = get_condition(trial_condition)\n",
    "        \n",
    "        run_condition = int(cols[int(np.where(headers == 'run_condition')[0])])\n",
    "        run_condition = get_condition(run_condition)\n",
    "\n",
    "        obs_trial_type = 'obs_' + run_condition\n",
    "\n",
    "        # congruent means trial_condition == run_condition\n",
    "        if run_condition == trial_condition:\n",
    "            if trial_condition == 'Pattern':\n",
    "                fb_trial_type = 'fb_Pattern_Congruent'\n",
    "            elif trial_condition == 'Social':\n",
    "                fb_trial_type = 'fb_Social_Congruent'\n",
    "            \n",
    "        else: # PE means trial_condition != run_condition\n",
    "            if trial_condition == 'Pattern':\n",
    "                fb_trial_type = 'fb_Social_PE'\n",
    "            elif trial_condition == 'Social':\n",
    "                fb_trial_type = 'fb_Pattern_PE'\n",
    "        \n",
    "        video_onset = float(cols[int(np.where(headers == 'obs_video_onset')[0])])\n",
    "        video_offset = float(cols[int(np.where(headers == 'obs_video_offset')[0])])  \n",
    "        video_duration = video_offset - video_onset\n",
    "        \n",
    "        fb_video_onset = float(cols[int(np.where(headers == 'fb_video_onset')[0])])\n",
    "        fb_video_offset = float(cols[int(np.where(headers == 'fb_video_offset')[0])])  \n",
    "        fb_video_duration = fb_video_offset - fb_video_onset\n",
    "\n",
    "        run = int(cols[int(np.where(headers == 'run_number')[0])])\n",
    "        \n",
    "        yield [video_onset, video_duration, obs_trial_type, run]\n",
    "        yield [fb_video_onset,fb_video_duration, fb_trial_type, run]\n",
    "        # yield [surprise_onset,surprise_duration, 'surprise_onset', run]\n",
    "        # yield [prediction_onset, prediction_duration, 'pred_onset', run]\n",
    "\n",
    "            \n",
    "\n",
    "def create_events_dataframe(task_csv, run):   \n",
    "    task_lines =[]       \n",
    "    # df = pd.DataFrame(columns=['onset','duration','trial_type'])\n",
    "    with open(task_csv, 'r') as task_csv_file:\n",
    "        task_lines.append(list(parse_task_lines(task_csv_file.readlines()[0:], logfile_headers)))\n",
    "\n",
    "    df = pd.DataFrame(task_lines[0], columns=['onset','duration','trial_type','run'])\n",
    "    df= df[df['run']==run].drop(columns=['run'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running subject 152\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 179\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 154\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 158\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 173\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 153\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 159\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 174\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 162\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 145\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 143\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 181\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 144\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 169\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 146\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 167\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 161\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 182\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 147\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 166\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 160\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 185\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 170\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 176\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 151\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 157\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 171\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 177\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "running subject 150\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n",
      "running subject 156\n",
      "saving regressor for video fb_Social_Congruent\n",
      "saving regressor for video fb_Social_PE\n",
      "saving regressor for video obs_Social\n",
      "saving regressor for video fb_Pattern_Congruent\n",
      "saving regressor for video fb_Pattern_PE\n",
      "saving regressor for video obs_Pattern\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res_dir = f'fmri_results/1stLvl/'\n",
    "if not os.path.isdir(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "\n",
    "for s in subjects_list:\n",
    "    print(f'running subject {s}')\n",
    "    sub_output_dir = res_dir + f'/{s}/'\n",
    "    if not os.path.isdir(sub_output_dir):\n",
    "        os.makedirs(sub_output_dir)\n",
    "        \n",
    "    task_file = glob.glob(logfiles_dir + f\"/*{s}*edited.txt\")\n",
    "    task_csv = task_file[0]\n",
    "    \n",
    "    for run in [1,2]:\n",
    "        events = create_events_dataframe(task_csv, run)\n",
    "\n",
    "        #get confounds info:\n",
    "        confounds_str = f'sub-{s}_task-socialpred_run-{run}_desc-confounds_timeseries.tsv'\n",
    "        cov = CreateConfoundMatrix(confounds_dir + confounds_str, confounds_of_interest, s, run)\n",
    "        \n",
    "        fmri_glm = FirstLevelModel(t_r=TR_Length,\n",
    "                           noise_model='ar3',\n",
    "                           standardize=True,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.012, mask_img=gm_mask_img,smoothing_fwhm=8)\n",
    "        \n",
    "        func_str = f'sub-{s}_socialpred_run{run}.nii.gz'\n",
    "        func_path = data_dir + func_str\n",
    "        fmri_img = nib.load(func_path)\n",
    "        fmri_glm = fmri_glm.fit(fmri_img, events, confounds=cov)\n",
    "        \n",
    "        # save design_matrix for every run\n",
    "        design_matrix = fmri_glm.design_matrices_[0]\n",
    "\n",
    "        plotting.plot_design_matrix(design_matrix, output_file=join(sub_output_dir, f'design_matrix_run{run}.png'))\n",
    "        contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "        # # extract the betas\n",
    "        for i in range(3):\n",
    "            print(f'saving regressor for video {design_matrix.columns[i]}')\n",
    "            eff = fmri_glm.compute_contrast(contrast_matrix[i],output_type='effect_size')\n",
    "            nii_file_path = sub_output_dir + f'/sub-{s}_run-{run}_beta_video-{design_matrix.columns[i]}_gm_masked.nii.gz'\n",
    "            nib.save(eff, nii_file_path)\n",
    "\n",
    "            eff = fmri_glm.compute_contrast(contrast_matrix[i],output_type='z_score')\n",
    "            nii_file_path = sub_output_dir + f'/sub-{s}_run-{run}_z_score_video-{design_matrix.columns[i]}_gm_masked.nii.gz'\n",
    "            nib.save(eff, nii_file_path)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
